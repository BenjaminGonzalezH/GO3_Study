{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56853acc",
   "metadata": {},
   "source": [
    "# Archivo a archivo\n",
    "Este archivo tiene el propósito de proporcionar el estudio de cada archivo existente dentro del código Rust del paquete de go3 para explicar su funcionamiento clave, asimismo, se toma la iniciativa de presentar dos razones fundamentales para determinar que una comparación con PyGoSemSim no se considera viable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c5bfca",
   "metadata": {},
   "source": [
    "## Código 1 - libs.rs\n",
    "Este es el archivo intermedio que permite la comunicación entre Python y Rust, por ende, ya se deduce que la implementación de las funcionalidades de este paquete son completamente hechas en Rust que es envuelto por el paquete pyo3 que permite invocarlas bajo la sintaxis del lenguaje de destino. A continuación el desglose linea a linea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142486f",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "// En esta sección se realiza la envoltura de los archivos Rust con pyo3 estableciendolo en\n",
    "// 3 pasos:\n",
    "use pyo3::prelude::*;           //Rust comprende Python (viceversa).\n",
    "use pyo3::types::PyModule;      //Rust entiende el concepto de módulo de Python.\n",
    "use pyo3::wrap_pyfunction;      //Python invoca código de Rust.\n",
    "\n",
    "// Se solicita la carga de tres archivo existentes en el mismo directorio en el que se\n",
    "// encuentra el archivo actual.\n",
    "pub mod go_loader;              // Lectura de archivos de entrada, relaciones e IC.\n",
    "pub mod go_ontology;            // --\n",
    "pub mod go_semantic;            // --\n",
    "\n",
    "// Dentro de cada uno de estos archivos mencionados previamente, se solicita la disponibilidad\n",
    "// de las funciones que se mencionan a continuación.\n",
    "use go_loader::{load_go_terms, load_gaf, build_term_counter};\n",
    "use go_ontology::{get_term_by_id, ancestors, common_ancestor, deepest_common_ancestor};\n",
    "use go_semantic::{term_ic, semantic_similarity, batch_similarity, compare_genes, compare_gene_pairs_batch, set_num_threads};\n",
    "\n",
    "// En esta sección se realiza la envoltura de todas las componentes invocadas anteriormente\n",
    "// de forma en que estas sean reconocidad como modulo de Python.\n",
    "#[pymodule]\n",
    "fn go3(_py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {\n",
    "\n",
    "    // Funciones añadidas por archivos.\n",
    "    m.add_function(wrap_pyfunction!(load_go_terms, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(load_gaf, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(build_term_counter, m)?)?;\n",
    "\n",
    "    m.add_function(wrap_pyfunction!(get_term_by_id, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(ancestors, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(common_ancestor, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(deepest_common_ancestor, m)?)?;\n",
    "\n",
    "    m.add_function(wrap_pyfunction!(set_num_threads, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(term_ic, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(semantic_similarity, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(batch_similarity, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(compare_genes, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(compare_gene_pairs_batch, m)?)?;\n",
    "\n",
    "    // Objetos o clases por archivo.\n",
    "    m.add_class::<go_ontology::PyGOTerm>()?;\n",
    "    m.add_class::<go_loader::GAFAnnotation>()?;\n",
    "    m.add_class::<go_loader::TermCounter>()?;\n",
    "\n",
    "    // Retroalimentación que indica exito o error en la migración de funciones.\n",
    "    Ok(())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bccaf8f",
   "metadata": {},
   "source": [
    "## Código 2 - goloader.rs\n",
    "Archivo encargado del procesamiento de los archivos .obo y gaf para la construcción de las relaciones jerarquicas entre terminos, relaciones gen a termino y el cálculo de IC de cada término existente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc783740",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "// ---------------- Librerias.\n",
    "use pyo3::prelude::*;                                               // Rust comprende Python (viceversa).\n",
    "use once_cell::sync::OnceCell;                                      // Implementación de variables globales de una sola carga.\n",
    "use rustc_hash::{FxHashMap as HashMap, FxHashSet as HashSet};       // Invocación de tablas hash.\n",
    "use std::io::{BufReader, BufRead};                                  // Lectura eficiente de archivos.\n",
    "use std::fs::File;                                                  // Apertura y manejo de archivos.\n",
    "use parking_lot::RwLock;                                            // Administración de hilos por semaforo.\n",
    "use std::path::Path;                                                // Administración de rutas.\n",
    "use std::fs;                                                        // Administración de entradas y salidas.\n",
    "use reqwest::blocking::get;                                         // Peticiones para obtención de recursos en internet.\n",
    "use rayon::prelude::*;                                              // Automatización del uso de todos los nucleos disponibles de un dispositivo.\n",
    "\n",
    "// ---------------- Componentes globales.\n",
    "// Declaración de entidades estáticas en memoria y global en toda la ejecución del código;\n",
    "// cabe señalar que estos son persistentes mientras el código se ejecuta y estos poseen la\n",
    "// capacidad de ser leidos por varios threads con bloqueo si se requiere escribir.\n",
    "use crate::go_ontology::{GOTerm, PyGOTerm, collect_ancestors, get_terms_or_error};\n",
    "pub static GO_TERMS_CACHE: OnceCell<RwLock<HashMap<String, GOTerm>>> = OnceCell::new();                 // Hash entre el GO_ID y su información.\n",
    "pub static GENE2GO_CACHE: OnceCell<RwLock<HashMap<String, Vec<String>>>> = OnceCell::new();             // Hash entre un gen y sus términos GO relacionados.\n",
    "pub static ANCESTORS_CACHE: OnceCell<RwLock<HashMap<String, HashSet<String>>>> = OnceCell::new();       // Hash entre un GO_ID y sus respectivos ancestros.\n",
    "pub static DCA_CACHE: OnceCell<RwLock<HashMap<(String, String), String>>> = OnceCell::new();            // DCA - Deep Common Ancestor entre un par de terminos.\n",
    "\n",
    "/// Struct representing a single annotation from a GAF file.\n",
    "/// \n",
    "/// Fields\n",
    "/// ------\n",
    "/// db_object_id : str\n",
    "///   The gene product identifier (e.g., UniProt ID).\n",
    "/// go_term : str\n",
    "///   The GO term ID (e.g., GO:0008150).\n",
    "/// evidence : str\n",
    "///   The evidence code for the annotation (e.g., IEA).\n",
    "/*De este componente se puede comprender que solamente del GAF se obtiene el db_object_id\n",
    "el go_term y la evidencia asociada a este mismo, siendo las tres columnas claves.*/\n",
    "#[pyclass]                      // Se considera una clase compatible con Python.\n",
    "#[derive(Clone)]                // Permite replicación/copia si es requerido.\n",
    "pub struct GAFAnnotation {\n",
    "    #[pyo3(get)]\n",
    "    pub db_object_id: String,\n",
    "    #[pyo3(get)]\n",
    "    pub go_term: String,\n",
    "    #[pyo3(get)]\n",
    "    pub evidence: String,\n",
    "}\n",
    "\n",
    "/// Struct holding annotation counts and information content (IC) for GO terms.\n",
    "///\n",
    "/// Fields\n",
    "/// ------\n",
    "/// counts : dict\n",
    "///   Mapping from GO term ID to annotation count.\n",
    "/// total_by_ns : dict\n",
    "///   Mapping from namespace to total annotation count.\n",
    "/// ic : dict\n",
    "///   Mapping from GO term ID to information content (IC).\n",
    "/*Estructura encargada de establecer la computación de information content (IC) de\n",
    "cada termino GO asociado.*/\n",
    "#[pyclass]\n",
    "#[derive(Clone)]\n",
    "pub struct TermCounter {\n",
    "    #[pyo3(get)]\n",
    "    pub counts: HashMap<String, usize>,         // term_id -> count\n",
    "    #[pyo3(get)]\n",
    "    pub total_by_ns: HashMap<String, usize>,    // namespace -> total annotations\n",
    "    #[pyo3(get)]\n",
    "    pub ic: HashMap<String, f64>,               // term_id -> IC\n",
    "}\n",
    "\n",
    "/// Parse a GO OBO file and return a map of GO term IDs to GOTerm structs.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// path : str\n",
    "///   Path to the OBO file.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// dict\n",
    "///   Map of GO term IDs to term structs.\n",
    "pub fn parse_obo(path: &str) -> HashMap<String, GOTerm> {\n",
    "    let contents = fs::read_to_string(path).expect(\"Can't open OBO file\");                          // Carga completa en memoria del archivo\n",
    "    let chunks = contents.split(\"[Term]\");                                                          // Separación de chunks de líneas según campo [Term]\n",
    "\n",
    "    let canonical_terms: Vec<GOTerm> = chunks                                                       // Procesamiento paralelo de GoTerms (ignora obsoletos o mal formateados).\n",
    "        .par_bridge()\n",
    "        .filter_map(parse_term_chunk)\n",
    "        .filter(|term| !term.is_obsolete)\n",
    "        .collect();\n",
    "\n",
    "    let mut term_map: HashMap<String, GOTerm> =                                                     // Preparación de memoria y configurar uso de hashing rápido.\n",
    "        HashMap::with_capacity_and_hasher(canonical_terms.len() * 2, Default::default());\n",
    "\n",
    "    for term in canonical_terms.into_iter() {                                                       // Uso de procesamiento de otros identificadores y términos asociados a un\n",
    "        // Collect the \"synonym group\": canonical + alts                                            // GoTerm de forma en que todos apunten a la misma información.\n",
    "        let mut all_ids = term.alt_ids.clone();\n",
    "        all_ids.push(term.id.clone());\n",
    "\n",
    "        // Build GOTerm copies for each ID\n",
    "        for id in &all_ids {\n",
    "            let mut clone = term.clone();\n",
    "            clone.id = id.clone();\n",
    "            clone.alt_ids = all_ids.clone(); // all point to the same group\n",
    "            term_map.insert(id.clone(), clone);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Compute children, levels, depths, etc.\n",
    "    compute_levels_and_depths(&mut term_map);                                                       // Se verifica profundidad/especifidad de cada término.\n",
    "\n",
    "    // Precompute ancestors for caching\n",
    "    let ancestors_map: HashMap<String, HashSet<String>> = term_map                                  // Se identifican (una sola vez) los ancestros a cada GoTerm.\n",
    "        .par_iter()\n",
    "        .map(|(id, _)| {\n",
    "            let ancestors = crate::go_ontology::collect_ancestors(id, &term_map)\n",
    "                .into_iter()\n",
    "                .map(|s| s.to_string())\n",
    "                .collect();\n",
    "            (id.clone(), ancestors)\n",
    "        })\n",
    "        .collect();\n",
    "    let _ = ANCESTORS_CACHE.set(RwLock::new(ancestors_map));                                        // Guardado en cache.\n",
    "\n",
    "    // Initialize DCA_CACHE\n",
    "    let _ = DCA_CACHE.set(RwLock::new(HashMap::default()));                                         // Se inicializa cache de ancestro más cercano (se calcula por demanda).\n",
    "\n",
    "    term_map                                                                                        // Se retorna mapeo de GoTermns.\n",
    "}\n",
    "\n",
    "/// Parse a chunk of text representing a single GO term from an OBO file.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// chunk : str\n",
    "///   Text chunk for a single term.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// Option[GOTerm]\n",
    "///   Parsed term or None if invalid/obsolete.\n",
    "fn parse_term_chunk(chunk: &str) -> Option<GOTerm> {\n",
    "    // Definición de la estructura de un término (dentro del archivo).\n",
    "    let mut term = GOTerm {\n",
    "        id: String::new(),                              // Identificador.\n",
    "        name: String::new(),                            // Nombre.\n",
    "        namespace: String::new(),                       // Ontología BP, MC, CC.\n",
    "        definition: String::new(),                      // Definición.\n",
    "        parents: Vec::new(),                            // Padres.\n",
    "        is_obsolete: false,                             // ¿Es obsoleto?\n",
    "        alt_ids: Vec::new(),                            // Ids alternativos.\n",
    "        replaced_by: None,                              // Reemplazado por... (si esta obsoleto).\n",
    "        consider: Vec::new(),                           // Considerar ¿Qué cosa?.\n",
    "        synonyms: Vec::new(),                           // Sinónimos.\n",
    "        xrefs: Vec::new(),                              // Referencias asociadas a...\n",
    "        relationships: Vec::new(),                      // Relaciones con otros términois.\n",
    "        comment: None,                                  // Comentarios.\n",
    "        children: Vec::new(),                           // Hijos.\n",
    "        level: None,                                    // Nivel.\n",
    "        depth: None,                                    // Profundidad/Especificidad.\n",
    "    };\n",
    "\n",
    "    let chunk = chunk.split(\"[Typedef]\").next().unwrap_or(chunk);       // Ignorar campos Typedef.\n",
    "\n",
    "    let lines: Vec<&str> = chunk\n",
    "        .lines()\n",
    "        .map(|l| l.trim())                               // eliminamos espacios a izquierda y derecha\n",
    "        .filter(|l| !l.is_empty())                       // quitamos líneas vacías\n",
    "        .collect();\n",
    "\n",
    "    if lines.is_empty() {\n",
    "        return None;\n",
    "    }\n",
    "    let mut valid = false;\n",
    "\n",
    "    // Verificación de campos que se obtienen de cada sección existente en Term.\n",
    "    for line in lines {\n",
    "        if line.starts_with(\"id: \") {                                               // Verificación para que sea válido (debe tener campo ID).\n",
    "            term.id = line[\"id: \".len()..].to_string();\n",
    "            valid = true;\n",
    "        } else if line.starts_with(\"name: \") {\n",
    "            term.name = line[\"name: \".len()..].to_string();\n",
    "        } else if line.starts_with(\"namespace: \") {\n",
    "            term.namespace = line[\"namespace: \".len()..].to_string();\n",
    "        } else if line.starts_with(\"def: \") {\n",
    "            term.definition = line[\"def: \".len()..].to_string();\n",
    "        } else if line.starts_with(\"is_a: \") {\n",
    "            let parent = line[\"is_a: \".len()..]\n",
    "                .split_whitespace()\n",
    "                .next()\n",
    "                .unwrap_or(\"\")\n",
    "                .to_string();\n",
    "            if !parent.is_empty() {\n",
    "                term.parents.push(parent);\n",
    "            }\n",
    "        } else if line.starts_with(\"alt_id: \") {\n",
    "            term.alt_ids.push(line[\"alt_id: \".len()..].to_string());\n",
    "        } else if line.starts_with(\"is_obsolete: true\") {\n",
    "            term.is_obsolete = true;\n",
    "        } else if line.starts_with(\"replaced_by: \") {\n",
    "            term.replaced_by = Some(line[\"replaced_by: \".len()..].to_string());\n",
    "        } else if line.starts_with(\"consider: \") {\n",
    "            term.consider.push(line[\"consider: \".len()..].to_string());\n",
    "        } else if line.starts_with(\"synonym: \") {\n",
    "            term.synonyms.push(line[\"synonym: \".len()..].to_string());\n",
    "        } else if line.starts_with(\"xref: \") {\n",
    "            term.xrefs.push(line[\"xref: \".len()..].to_string());\n",
    "        } else if line.starts_with(\"relationship: \") {\n",
    "            let rel_def = &line[\"relationship: \".len()..];\n",
    "            let mut parts = rel_def.split_whitespace();\n",
    "            if let (Some(rel), Some(target)) = (parts.next(), parts.next()) {\n",
    "                term.relationships.push((rel.to_string(), target.to_string()));\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if valid {\n",
    "        Some(term)                                       // Si el termino es válido lo devuelve, en caso contrario se ignora.\n",
    "    } else {\n",
    "        None\n",
    "    }\n",
    "}\n",
    "\n",
    "/// Compute the level and depth for each GO term in the ontology.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// terms : dict\n",
    "///   Mutable map of GO terms.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// None\n",
    "///   Updates the `level` and `depth` fields of each term in-place.\n",
    "pub fn compute_levels_and_depths(terms: &mut HashMap<String, GOTerm>) {\n",
    "    \n",
    "    // Paso 1: construir mapa de hijos teniendo en consideración las relaciones\n",
    "    // is_a para establecer jerarquía padre-hijo.\n",
    "    let mut child_map: HashMap<String, Vec<String>> = HashMap::default();\n",
    "    for (id, term) in terms.iter() {\n",
    "        for parent in &term.parents {\n",
    "            child_map.entry(parent.clone()).or_default().push(id.clone());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Paso 2: inicializar level como una componente que identifica la distancia mínima\n",
    "    // entre el término raiz y el termino en estudio. Esto como función recursiva interna\n",
    "    // que selecciona camino según los padres de menor distancia.\n",
    "    fn init_level(\n",
    "        term_id: &str,\n",
    "        terms: &mut HashMap<String, GOTerm>,\n",
    "        visiting: &mut HashSet<String>,\n",
    "    ) -> usize {\n",
    "        if visiting.contains(term_id) {\n",
    "            // Ciclo detectado: se evita recursión infinita\n",
    "            eprintln!(\"⚠️ Ciclo detectado en level: {}\", term_id);\n",
    "            return 0;\n",
    "        }\n",
    "\n",
    "        if let Some(level) = terms.get(term_id).and_then(|t| t.level) {\n",
    "            return level;\n",
    "        }\n",
    "\n",
    "        visiting.insert(term_id.to_string());\n",
    "\n",
    "        let parents = terms\n",
    "            .get(term_id)\n",
    "            .map(|t| t.parents.clone())\n",
    "            .unwrap_or_default();\n",
    "\n",
    "        let level = if parents.is_empty() {\n",
    "            0\n",
    "        } else {\n",
    "            parents\n",
    "                .iter()\n",
    "                .map(|p| init_level(p, terms, visiting))\n",
    "                .min()\n",
    "                .unwrap_or(0) + 1\n",
    "        };\n",
    "\n",
    "        visiting.remove(term_id);\n",
    "        if let Some(term) = terms.get_mut(term_id) {\n",
    "            term.level = Some(level);\n",
    "        }\n",
    "\n",
    "        level\n",
    "    }\n",
    "\n",
    "    // Paso 3: inicializar depth como la distancia más larga a la raíz. Mismo concepto \n",
    "    // que punto anterior.\n",
    "    fn init_depth(\n",
    "        term_id: &str,\n",
    "        terms: &mut HashMap<String, GOTerm>,\n",
    "        visiting: &mut HashSet<String>,\n",
    "    ) -> usize {\n",
    "        if visiting.contains(term_id) {\n",
    "            eprintln!(\"Ciclo detectado en depth: {}\", term_id);\n",
    "            return 0;\n",
    "        }\n",
    "\n",
    "        if let Some(depth) = terms.get(term_id).and_then(|t| t.depth) {\n",
    "            return depth;\n",
    "        }\n",
    "\n",
    "        visiting.insert(term_id.to_string());\n",
    "\n",
    "        let parents = terms\n",
    "            .get(term_id)\n",
    "            .map(|t| t.parents.clone())\n",
    "            .unwrap_or_default();\n",
    "\n",
    "        let depth = if parents.is_empty() {\n",
    "            0\n",
    "        } else {\n",
    "            parents\n",
    "                .iter()\n",
    "                .map(|p| init_depth(p, terms, visiting))\n",
    "                .max()\n",
    "                .unwrap_or(0) + 1\n",
    "        };\n",
    "\n",
    "        visiting.remove(term_id);\n",
    "        if let Some(term) = terms.get_mut(term_id) {\n",
    "            term.depth = Some(depth);\n",
    "        }\n",
    "\n",
    "        depth\n",
    "    }\n",
    "\n",
    "    // Paso 4: recorrer todos los términos y calcular level + depth como llamados\n",
    "    // a las funciones por cada ids.\n",
    "    let ids: Vec<String> = terms.keys().cloned().collect();\n",
    "    for id in &ids {\n",
    "        let mut visiting = HashSet::default();\n",
    "        init_level(id, terms, &mut visiting);\n",
    "\n",
    "        let mut visiting = HashSet::default();\n",
    "        init_depth(id, terms, &mut visiting);\n",
    "    }\n",
    "\n",
    "    // Paso 5: rellenar el campo children con los hijos (solo vía is_a).\n",
    "    for (parent, children) in child_map {\n",
    "        if let Some(term) = terms.get_mut(&parent) {\n",
    "            term.children = children;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/// Download the latest GO OBO file if not present locally.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// None\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// str\n",
    "///   Path to the downloaded or existing OBO file.\n",
    "// Obtención de archivo .obo verificando si este existe en la ruta de destino, por defecto,\n",
    "// descarga la versión básica ¿Por qué se tomo esa decisión?.\n",
    "pub fn download_obo() -> Result<String, String> {\n",
    "    let obo_path = \"go-basic.obo\";\n",
    "    if Path::new(obo_path).exists() {\n",
    "        return Ok(obo_path.to_string());\n",
    "    }\n",
    "\n",
    "    let url = \"http://purl.obolibrary.org/obo/go/go-basic.obo\";\n",
    "    println!(\"Descargando ontología desde: {}\", url);\n",
    "    let response = get(url).map_err(|e| e.to_string())?;\n",
    "\n",
    "    let content = response.text().map_err(|e| e.to_string())?;\n",
    "    fs::write(obo_path, content).map_err(|e| e.to_string())?;\n",
    "\n",
    "    Ok(obo_path.to_string())\n",
    "}\n",
    "\n",
    "/// Load GO terms from an OBO file and cache them globally.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// path : Optional[str]\n",
    "///   Optional path to the OBO file.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// list of PyGOTerm\n",
    "///   List of GO terms as Python objects.\n",
    "// En esta función se realiza el llamado al parseo de GoTerms y su guardado en chache\n",
    "// para no necesitar re-ejecuciones de la función.\n",
    "#[pyfunction]\n",
    "#[pyo3(signature = (path=None))]\n",
    "pub fn load_go_terms(path: Option<String>) -> PyResult<Vec<PyGOTerm>> {\n",
    "    let path = path.unwrap_or_else(|| download_obo().unwrap());\n",
    "    let terms_map = parse_obo(&path);\n",
    "\n",
    "    // Guardar en la caché global\n",
    "    let _ = GO_TERMS_CACHE.set(RwLock::new(terms_map.clone()));\n",
    "\n",
    "    // Devolver lista de PyGOTerm (compatibilidad con Python).\n",
    "    let terms_vec = terms_map\n",
    "        .into_iter()\n",
    "        .map(|(_, v)| PyGOTerm::from(&v))\n",
    "        .collect();\n",
    "\n",
    "    Ok(terms_vec)\n",
    "}\n",
    "\n",
    "/// Load a GAF annotation file and cache the gene-to-GO mapping.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// path : str\n",
    "///   Path to the GAF file.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// list of GAFAnnotation\n",
    "///   List of parsed GAF annotations.\n",
    "// \n",
    "#[pyfunction]\n",
    "pub fn load_gaf(path: String) -> PyResult<Vec<GAFAnnotation>> {\n",
    "    // Se verifica acceso al archivo .gaf existente, en caso de que este no pueda ser \n",
    "    // accedido, entonces la función termina.\n",
    "    let file = File::open(&path)\n",
    "        .map_err(|e| pyo3::exceptions::PyIOError::new_err(e.to_string()))?;\n",
    "    let reader = BufReader::new(file);\n",
    "\n",
    "    // Get the loaded GO terms to check for obsolete terms.\n",
    "    // Recordar: Debieron haberse cargado en cache los go terms.\n",
    "    let terms = match crate::go_ontology::get_terms_or_error() {\n",
    "        Ok(t) => t,\n",
    "        Err(e) => return Err(e),\n",
    "    };\n",
    "\n",
    "    let mut annotations: Vec<GAFAnnotation> = Vec::new();                   // Vector de anotaciones de GAF (parte vacía).\n",
    "    let mut gene2go: HashMap<String, Vec<String>> = HashMap::default();     // Relación de genes a términos.\n",
    "\n",
    "    // Lectura linea a linea filtrando aquellas que no empiecen con '!'.\n",
    "    for line in reader.lines().filter_map(Result::ok).filter(|l| !l.starts_with('!')) {\n",
    "        let cols: Vec<&str> = line.split('\\t').collect();                   // Identificar columnas mediante una separación por tabuladores (son 7).\n",
    "        if cols.len() < 7 {                                                 // Debe tener como mínimo 7 campos como mínimo.\n",
    "            continue;\n",
    "        }\n",
    "\n",
    "        // Columnas consideradas de cada linea válida.\n",
    "        let db_object_id = cols[1].to_string();\n",
    "        let qualifier = cols[3].to_string();\n",
    "        let mut go_term = cols[4].to_string();\n",
    "        let evidence = cols[6].to_string();\n",
    "        let gene = cols[2].to_string();\n",
    "\n",
    "        // Se ignoran registros de genes con terminos sin evidencia sustentada,\n",
    "        // asimismo de asociaciones del tipo \"El gen NO hace esto\".\n",
    "        // Filter out ND annotations.\n",
    "        if evidence == \"ND\" {\n",
    "            continue;\n",
    "        }\n",
    "        // Skip NOT annotations.\n",
    "        if qualifier.contains(\"NOT\") {\n",
    "            continue;\n",
    "        }\n",
    "\n",
    "\n",
    "        // Resolve obsolete terms\n",
    "        if let Some(term) = terms.get(&go_term) {\n",
    "            if term.is_obsolete {\n",
    "                if let Some(ref replacement) = term.replaced_by {\n",
    "                    // Use the replacement term instead\n",
    "                    go_term = replacement.clone();\n",
    "                } else if !term.consider.is_empty() {\n",
    "                    // If there are \"consider\" terms, choose the first one\n",
    "                    go_term = term.consider[0].clone();\n",
    "                } else {\n",
    "                    // If no replacement, drop the annotation\n",
    "                    continue;\n",
    "                }\n",
    "            }\n",
    "        } else {\n",
    "            // GO term not found at all\n",
    "            continue;\n",
    "        }\n",
    "\n",
    "        // Add annotation.\n",
    "        annotations.push(GAFAnnotation {\n",
    "            db_object_id: db_object_id.clone(),\n",
    "            go_term: go_term.clone(),\n",
    "            evidence,\n",
    "        });\n",
    "\n",
    "        // Update gene -> GO mapping\n",
    "        gene2go.entry(gene).or_default().push(go_term);\n",
    "    }\n",
    "\n",
    "    // Save in global cache.\n",
    "    let _ = GENE2GO_CACHE.set(RwLock::new(gene2go));\n",
    "\n",
    "    Ok(annotations)\n",
    "}\n",
    "/// Build a term counter (counts, IC) from GAF annotations.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// py_annotations : list of GAFAnnotation\n",
    "///   List of GAFAnnotation Python objects.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// TermCounter\n",
    "///   Struct with counts and IC values.\n",
    "\n",
    "#[pyfunction]\n",
    "pub fn build_term_counter(\n",
    "    py: Python<'_>,\n",
    "    py_annotations: Vec<Py<GAFAnnotation>>,\n",
    ") -> PyResult<TermCounter> {\n",
    "    // Obtener los términos GO desde el caché global.\n",
    "    let terms = get_terms_or_error()?;\n",
    "\n",
    "    // Convertir las anotaciones de Py<GAFAnnotation> a GAFAnnotation (Rust).\n",
    "    let annotations: Vec<GAFAnnotation> = py_annotations\n",
    "        .into_iter()\n",
    "        .map(|py_ann| py_ann.extract(py))\n",
    "        .collect::<PyResult<_>>()?;\n",
    "\n",
    "    // Llamar a la función de conteo interna.\n",
    "    Ok(_build_term_counter(&annotations, &terms))\n",
    "}\n",
    "\n",
    "/// Internal: Build a term counter from Rust GAFAnnotation and GOTerm.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// annotations : list of GAFAnnotation\n",
    "///   List of GAFAnnotation structs.\n",
    "/// terms : dict\n",
    "///   Map of GO terms.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// TermCounter\n",
    "///   Struct with counts and IC values.\n",
    "fn _build_term_counter(\n",
    "    annotations: &[GAFAnnotation],\n",
    "    terms: &HashMap<String, GOTerm>,\n",
    ") -> TermCounter {\n",
    "    use rayon::prelude::*;                          // Motor de paralelismo.\n",
    "    use std::sync::Mutex;                           // Controlador de exclusión mutua.\n",
    "\n",
    "    // Parallel: build obj_to_terms - Objeto con toda la relación entre los términos y las anotaciones\n",
    "    // procesadas en el GAF.\n",
    "    let obj_to_terms: HashMap<&str, HashSet<String>> = {\n",
    "        let obj_to_terms_mutex: Mutex<HashMap<&str, HashSet<String>>> = Mutex::new(HashMap::default());\n",
    "        annotations.par_iter().for_each(|ann| {\n",
    "            let go_id = ann.go_term.as_str();\n",
    "            let mut term_set: HashSet<String> = collect_ancestors(go_id, terms);\n",
    "            term_set.insert(go_id.to_string());\n",
    "            let mut map = obj_to_terms_mutex.lock().unwrap();\n",
    "            map.entry(ann.db_object_id.as_str())\n",
    "                .or_default()\n",
    "                .extend(term_set);\n",
    "        });\n",
    "        obj_to_terms_mutex.into_inner().unwrap()\n",
    "    };\n",
    "\n",
    "    // Parallel: build counts and total_by_ns - Conteo de cada gen presente por termino y\n",
    "    // cantidad de genes únicos por ontología.\n",
    "    let (counts, total_by_ns) = {\n",
    "        let counts_mutex: Mutex<HashMap<String, usize>> = Mutex::new(HashMap::default());\n",
    "        let total_by_ns_mutex: Mutex<HashMap<String, usize>> = Mutex::new(HashMap::default());\n",
    "        obj_to_terms.values().collect::<Vec<_>>().par_iter().for_each(|term_ids| {\n",
    "            let mut namespaces_seen = HashSet::default();\n",
    "            for term_id in *term_ids {\n",
    "                if let Some(term) = terms.get(term_id.as_str()) {\n",
    "                    let mut counts = counts_mutex.lock().unwrap();\n",
    "                    *counts.entry(term_id.to_string()).or_insert(0) += 1;\n",
    "                    namespaces_seen.insert(term.namespace.as_str());\n",
    "                }\n",
    "            }\n",
    "            for ns in namespaces_seen {\n",
    "                let mut total_by_ns = total_by_ns_mutex.lock().unwrap();\n",
    "                *total_by_ns.entry(ns.to_string()).or_insert(0) += 1;\n",
    "            }\n",
    "        });\n",
    "        (counts_mutex.into_inner().unwrap(), total_by_ns_mutex.into_inner().unwrap())\n",
    "    };\n",
    "\n",
    "    // Calcular IC (secuencial, as it's fast).\n",
    "    let mut ic: HashMap<String, f64> = HashMap::default();\n",
    "    for (term_id, count) in &counts {\n",
    "        if let Some(term) = terms.get(term_id.as_str()) {\n",
    "            let total = total_by_ns.get(&term.namespace).copied().unwrap_or(1);\n",
    "            let freq = *count as f64 / total as f64;\n",
    "            let info_content = if freq > 0.0 { -freq.ln() } else { 0.0 };\n",
    "            ic.insert(term_id.clone(), info_content);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    TermCounter {\n",
    "        counts,\n",
    "        total_by_ns,\n",
    "        ic,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c3630",
   "metadata": {},
   "source": [
    "## Código 3 - go_ontology.rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18180c6c",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "// ---------------- Librerias.\n",
    "use rustc_hash::{FxHashMap as HashMap, FxHashSet as HashSet};       // Invocación de tablas hash.      \n",
    "use pyo3::prelude::*;                                               // Rust comprende Python (viceversa).\n",
    "use pyo3::types::PyString;                                          // Se invoca tipo de dato string de Python.\n",
    "use crate::go_loader::{GO_TERMS_CACHE, GENE2GO_CACHE};              // Se obtiene la cache generada en go_loader (si existe).\n",
    "use pyo3::exceptions::PyValueError;                                 // Se invoca 'error por valor' de Python.\n",
    "\n",
    "/// Struct representing a Gene Ontology (GO) term.\n",
    "///\n",
    "/// Fields\n",
    "/// ------\n",
    "/// id : str\n",
    "///   GO term identifier (e.g., GO:0006397).\n",
    "/// name : str\n",
    "///   Human-readable name of the term.\n",
    "/// namespace : str\n",
    "///   Ontology namespace (e.g., biological_process).\n",
    "/// definition : str\n",
    "///   Textual definition of the term.\n",
    "/// parents : list of str\n",
    "///   List of parent GO term IDs (is_a relationships).\n",
    "/// children : list of str\n",
    "///   List of child GO term IDs (is_a relationships).\n",
    "/// depth : Optional[int]\n",
    "///   Maximum distance to a root term (None if not computed).\n",
    "/// level : Optional[int]\n",
    "///   Minimum distance to a root term (None if not computed).\n",
    "/// is_obsolete : bool\n",
    "///   True if the term is obsolete.\n",
    "/// alt_ids : list of str\n",
    "///   Alternative GO IDs for this term.\n",
    "/// replaced_by : Optional[str]\n",
    "///   If obsolete, the term that replaces this one.\n",
    "/// consider : list of str\n",
    "///   Suggested replacement terms if obsolete.\n",
    "/// synonyms : list of str\n",
    "///   List of synonyms.\n",
    "/// xrefs : list of str\n",
    "///   Cross-references to other databases.\n",
    "/// relationships : list of (str, str)\n",
    "///   Other relationships (e.g., part_of).\n",
    "/// comment : Optional[str]\n",
    "///   Additional comments.\n",
    "#[derive(Clone)]\n",
    "pub struct GOTerm {\n",
    "    pub id: String,\n",
    "    pub name: String,\n",
    "    pub namespace: String,\n",
    "    pub definition: String,\n",
    "    pub parents: Vec<String>,\n",
    "    pub children: Vec<String>,\n",
    "    pub depth: Option<usize>,\n",
    "    pub level: Option<usize>,\n",
    "    pub is_obsolete: bool,\n",
    "    pub alt_ids: Vec<String>,\n",
    "    pub replaced_by: Option<String>,\n",
    "    pub consider: Vec<String>,\n",
    "    pub synonyms: Vec<String>,\n",
    "    pub xrefs: Vec<String>,\n",
    "    pub relationships: Vec<(String, String)>,\n",
    "    pub comment: Option<String>,\n",
    "}\n",
    "\n",
    "/// Python-exposed struct representing a GO term (for use in the Python API).\n",
    "///\n",
    "/// Fields\n",
    "/// ------\n",
    "/// id : str\n",
    "///   GO term identifier.\n",
    "/// name : str\n",
    "///   Human-readable name of the term.\n",
    "/// namespace : str\n",
    "///   Ontology namespace.\n",
    "/// definition : str\n",
    "///   Textual definition of the term.\n",
    "/// parents : list of str\n",
    "///   List of parent GO term IDs.\n",
    "/// children : list of str\n",
    "///   List of child GO term IDs.\n",
    "/// depth : Optional[int]\n",
    "///   Maximum distance to a root term.\n",
    "/// level : Optional[int]\n",
    "///   Minimum distance to a root term.\n",
    "/// is_obsolete : bool\n",
    "///   True if the term is obsolete.\n",
    "/// alt_ids : list of str\n",
    "///   Alternative GO IDs for this term.\n",
    "/// replaced_by : Optional[str]\n",
    "///   If obsolete, the term that replaces this one.\n",
    "/// consider : list of str\n",
    "///   Suggested replacement terms if obsolete.\n",
    "/// synonyms : list of str\n",
    "///   List of synonyms.\n",
    "/// xrefs : list of str\n",
    "///   Cross-references to other databases.\n",
    "/// relationships : list of (str, str)\n",
    "///   Other relationships (e.g., part_of).\n",
    "/// comment : Optional[str]\n",
    "///   Additional comments.\n",
    "#[pyclass]\n",
    "#[derive(Clone)]\n",
    "pub struct PyGOTerm {\n",
    "    #[pyo3(get)] pub id: String,\n",
    "    #[pyo3(get)] pub name: String,\n",
    "    #[pyo3(get)] pub namespace: String,\n",
    "    #[pyo3(get)] pub definition: String,\n",
    "    #[pyo3(get)] pub parents: Vec<String>,\n",
    "    #[pyo3(get)] pub children: Vec<String>,\n",
    "    #[pyo3(get)] pub depth: Option<usize>,\n",
    "    #[pyo3(get)] pub level: Option<usize>,\n",
    "    #[pyo3(get)] pub is_obsolete: bool,\n",
    "    #[pyo3(get)] pub alt_ids: Vec<String>,\n",
    "    #[pyo3(get)] pub replaced_by: Option<String>,\n",
    "    #[pyo3(get)] pub consider: Vec<String>,\n",
    "    #[pyo3(get)] pub synonyms: Vec<String>,\n",
    "    #[pyo3(get)] pub xrefs: Vec<String>,\n",
    "    #[pyo3(get)] pub relationships: Vec<(String, String)>,\n",
    "    #[pyo3(get)] pub comment: Option<String>,\n",
    "}\n",
    "\n",
    "impl From<&GOTerm> for PyGOTerm {\n",
    "    fn from(term: &GOTerm) -> Self {\n",
    "        Self {\n",
    "            id: term.id.clone(),\n",
    "            name: term.name.clone(),\n",
    "            namespace: term.namespace.clone(),\n",
    "            definition: term.definition.clone(),\n",
    "            parents: term.parents.clone(),\n",
    "            children: term.children.clone(),\n",
    "            depth: term.depth,\n",
    "            level: term.level,\n",
    "            is_obsolete: term.is_obsolete,\n",
    "            alt_ids: term.alt_ids.clone(),\n",
    "            replaced_by: term.replaced_by.clone(),\n",
    "            consider: term.consider.clone(),\n",
    "            synonyms: term.synonyms.clone(),\n",
    "            xrefs: term.xrefs.clone(),\n",
    "            relationships: term.relationships.clone(),\n",
    "            comment: term.comment.clone(),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[pymethods]\n",
    "impl PyGOTerm {\n",
    "    fn __repr__(slf: &Bound<'_, Self>) -> PyResult<String> {\n",
    "        let class_name: Bound<'_, PyString> = slf.get_type().qualname()?;\n",
    "        let s = slf.borrow();\n",
    "        Ok(format!(\n",
    "            \"{} id: {}\\nname: {}\\nnamespace: {}\\ndefinition: {}\\nparents: {:?}\\nchildren: {:?}\\ndepth: {:?}\\nlevel: {:?}\\nis_obsolete: {}\\nalt_ids: {:?}\\nreplaced_by: {:?}\\nconsider: {:?}\\nsynonyms: {:?}\\nxrefs: {:?}\\nrelationships: {:?}\\ncomments: {:?}\",\n",
    "            class_name, s.id, s.name, s.namespace, s.definition, s.parents, s.children, s.depth, s.level,\n",
    "            s.is_obsolete, s.alt_ids, s.replaced_by, s.consider, s.synonyms, s.xrefs, s.relationships, s.comment\n",
    "        ))\n",
    "    }\n",
    "}\n",
    "\n",
    "impl From<PyGOTerm> for GOTerm {\n",
    "    fn from(py_term: PyGOTerm) -> Self {\n",
    "        Self {\n",
    "            id: py_term.id,\n",
    "            name: py_term.name,\n",
    "            namespace: py_term.namespace,\n",
    "            definition: py_term.definition,\n",
    "            parents: py_term.parents,\n",
    "            children: py_term.children,\n",
    "            depth: py_term.depth,\n",
    "            level: py_term.level,\n",
    "            is_obsolete: py_term.is_obsolete,\n",
    "            alt_ids: py_term.alt_ids,\n",
    "            replaced_by: py_term.replaced_by,\n",
    "            consider: py_term.consider,\n",
    "            synonyms: py_term.synonyms,\n",
    "            xrefs: py_term.xrefs,\n",
    "            relationships: py_term.relationships,\n",
    "            comment: py_term.comment,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/// Get a read lock on the global GO terms map, or error if not loaded.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// None\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// RwLockReadGuard<HashMap<String, GOTerm>>\n",
    "///   Read guard for the GO terms map.\n",
    "pub fn get_terms_or_error<'a>() -> PyResult<parking_lot::RwLockReadGuard<'a, HashMap<String, GOTerm>>> {\n",
    "    Ok(\n",
    "        GO_TERMS_CACHE\n",
    "            .get()\n",
    "            .ok_or_else(|| pyo3::exceptions::PyRuntimeError::new_err(\"GO terms not loaded. Call go3.load_go_terms() first.\"))?\n",
    "            .read()\n",
    "    )\n",
    "}\n",
    "\n",
    "/// Get a read lock on the global gene-to-GO mapping, or error if not loaded.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// None\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// RwLockReadGuard<HashMap<String, Vec<String>>>\n",
    "///   Read guard for the gene2go map.\n",
    "pub fn get_gene2go_or_error<'a>() -> PyResult<parking_lot::RwLockReadGuard<'a, HashMap<String, Vec<String>>>> {\n",
    "    Ok(\n",
    "        GENE2GO_CACHE\n",
    "            .get()\n",
    "            .ok_or_else(|| pyo3::exceptions::PyRuntimeError::new_err(\"Gene2GO mapping not loaded. Call go3.load_gene2go() first.\"))?\n",
    "            .read()\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "/// Get the PyGOTerm object for a given GO term ID.\n",
    "///\n",
    "/// Raises:\n",
    "///     ValueError: If the GO term does not exist in the ontology.\n",
    "#[pyfunction]\n",
    "pub fn get_term_by_id(go_id: &str) -> PyResult<PyGOTerm> {\n",
    "    let terms = get_terms_or_error()?;\n",
    "    match terms.get(go_id) {\n",
    "        Some(term) => Ok(PyGOTerm::from(term)),\n",
    "        None => Err(PyValueError::new_err(format!(\n",
    "            \"GO term '{}' not found in ontology\",\n",
    "            go_id\n",
    "        ))),\n",
    "    }\n",
    "}\n",
    "\n",
    "/// Collect all ancestors of a GO term (recursively via is_a).\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// go_id : str\n",
    "///   GO term ID.\n",
    "/// terms : dict\n",
    "///   Map of GO terms.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// HashSet<String>\n",
    "///   Set of ancestor GO term IDs.\n",
    "pub fn collect_ancestors(go_id: &str, terms: &HashMap<String, GOTerm>) -> HashSet<String> {\n",
    "    // Try to use the precomputed cache if available\n",
    "    if let Some(lock) = crate::go_loader::ANCESTORS_CACHE.get() {\n",
    "        let cache = lock.read();\n",
    "        if let Some(ancestors) = cache.get(go_id) {\n",
    "            return ancestors.clone();\n",
    "        }\n",
    "    }\n",
    "    // Fallback: original computation\n",
    "    let mut visited = HashSet::default();\n",
    "    let mut stack = vec![go_id];\n",
    "    while let Some(current) = stack.pop() {\n",
    "        if visited.insert(current.to_string()) {\n",
    "            if let Some(term) = terms.get(current) {\n",
    "                for parent in &term.parents {\n",
    "                    stack.push(parent);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "//    visited.remove(go_id);\n",
    "    visited\n",
    "}\n",
    "\n",
    "/// Returns the list of all ancestors in the ontology for the given GO Term.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// go_id : str\n",
    "///   GO term ID.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// list of str\n",
    "///   List of IDs of all the ancestors in the ontology.\n",
    "#[pyfunction]\n",
    "pub fn ancestors(go_id: &str) -> PyResult<Vec<String>> {\n",
    "    let terms = get_terms_or_error()?;\n",
    "    let visited = collect_ancestors(go_id, &terms);\n",
    "    Ok(visited.into_iter().collect())\n",
    "}\n",
    "\n",
    "/// Returns the list of all the common ancestors in the ontology for the given GO Terms.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// go_id1 : str\n",
    "///   GO term ID 1.\n",
    "/// go_id2 : str\n",
    "///   GO term ID 2.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// list of str\n",
    "///   List of IDs of all the common ancestors in the ontology.\n",
    "#[pyfunction]\n",
    "pub fn common_ancestor(go_id1: &str, go_id2: &str) -> PyResult<Vec<String>> {\n",
    "    let terms = get_terms_or_error()?;\n",
    "    let set1 = collect_ancestors(go_id1, &terms);\n",
    "    let set2 = collect_ancestors(go_id2, &terms);\n",
    "    let mut common: Vec<String> = set1.intersection(&set2).map(|s| (*s).to_string()).collect();\n",
    "    common.sort_unstable();\n",
    "    Ok(common)\n",
    "}\n",
    "\n",
    "/// Returns the deepest common ancestor in the ontology for the given GO Terms.\n",
    "///\n",
    "/// Arguments\n",
    "/// ---------\n",
    "/// go_id1 : str\n",
    "///   GO term ID 1.\n",
    "/// go_id2 : str\n",
    "///   GO term ID 2.\n",
    "///\n",
    "/// Returns\n",
    "/// -------\n",
    "/// Option<String>\n",
    "///   ID of the deepest common ancestor in the ontology.\n",
    "#[pyfunction]\n",
    "pub fn deepest_common_ancestor(go_id1: &str, go_id2: &str) -> PyResult<Option<String>> {\n",
    "    let terms = get_terms_or_error()?;\n",
    "\n",
    "    if !terms.contains_key(go_id1) {\n",
    "        return Err(PyValueError::new_err(format!(\n",
    "            \"GO term '{}' not found in ontology\",\n",
    "            go_id1\n",
    "        )));\n",
    "    }\n",
    "    if !terms.contains_key(go_id2) {\n",
    "        return Err(PyValueError::new_err(format!(\n",
    "            \"GO term '{}' not found in ontology\",\n",
    "            go_id2\n",
    "        )));\n",
    "    }\n",
    "\n",
    "    let (id_a, id_b) = if go_id1 <= go_id2 {\n",
    "        (go_id1, go_id2)\n",
    "    } else {\n",
    "        (go_id2, go_id1)\n",
    "    };\n",
    "\n",
    "    // Try to use the DCA cache if available\n",
    "    if let Some(lock) = crate::go_loader::DCA_CACHE.get() {\n",
    "        let cache = lock.write();\n",
    "        if let Some(result) = cache.get(&(id_a.to_string(), id_b.to_string())) {\n",
    "            return Ok(Some(result.clone()));\n",
    "        }\n",
    "    }\n",
    "\n",
    "    let set1 = collect_ancestors(id_a, &terms);\n",
    "    let set2 = collect_ancestors(id_b, &terms);\n",
    "    let mut best = None;\n",
    "    let mut max_depth = 0;\n",
    "    for term_id in set1.intersection(&set2) {\n",
    "        if let Some(term) = terms.get(term_id) {\n",
    "            if let Some(depth) = term.depth {\n",
    "                if depth >= max_depth {\n",
    "                    max_depth = depth;\n",
    "                    best = Some(term_id.to_string());\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Store the result in the cache if available\n",
    "    if let Some(lock) = crate::go_loader::DCA_CACHE.get() {\n",
    "        let mut cache = lock.write();\n",
    "        if let Some(ref dca) = best {\n",
    "            cache.insert((id_a.to_string(), id_b.to_string()), dca.clone());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Ok(best)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
